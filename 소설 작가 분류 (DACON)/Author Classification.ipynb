{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **소설 작가 분류 AI 경진대회 ** - 데이콘\n",
    "\n",
    "https://dacon.io/competitions/official/235670/overview/description\n",
    "\n",
    "[주제] \n",
    "\n",
    "**CSV 파일의 'text'를 분석해서 'author' 예측**\n",
    "\n",
    "[과정]\n",
    "* pandas를 통해 읽어와 train set과 test set으으로 분리(3:1)\n",
    "* train set으로 학습하고, test set으로 평가\n",
    "\n",
    "[제출 내용]\n",
    "* 머신러닝 기법 중 적절한 것들을 선택해 제일 좋은 모형 찾기\n",
    "* train set과 test set에 대한 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-데이터-준비\" data-toc-modified-id=\"1.-데이터-준비-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><strong>1. 데이터 준비</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-train-set과-test-set-분할(비율-3:1)\" data-toc-modified-id=\"1.1-train-set과-test-set-분할(비율-3:1)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>1.1 train set과 test set 분할(비율 3:1)</a></span></li><li><span><a href=\"#1.2-데이터-확인\" data-toc-modified-id=\"1.2-데이터-확인-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>1.2 데이터 확인</a></span></li><li><span><a href=\"#1.3-정규표현식을-이용한-토크나이저-함수-정의\" data-toc-modified-id=\"1.3-정규표현식을-이용한-토크나이저-함수-정의-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><strong>1.3 정규표현식을 이용한 토크나이저 함수 정의</strong></a></span></li><li><span><a href=\"#1.4-TfidfVectorizer에-토큰화-결과를-입력으로-사용\" data-toc-modified-id=\"1.4-TfidfVectorizer에-토큰화-결과를-입력으로-사용-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span><strong>1.4 TfidfVectorizer에 토큰화 결과를 입력으로 사용</strong></a></span></li><li><span><a href=\"#1.5-첫-번째-문서에-대해서-200개만-확인\" data-toc-modified-id=\"1.5-첫-번째-문서에-대해서-200개만-확인-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>1.5 첫 번째 문서에 대해서 200개만 확인</a></span></li></ul></li><li><span><a href=\"#2.-문서-분류-알고리즘에-적용\" data-toc-modified-id=\"2.-문서-분류-알고리즘에-적용-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span><strong>2. 문서 분류 알고리즘에 적용</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-나이브-베이즈-분류기-이용\" data-toc-modified-id=\"2.1-나이브-베이즈-분류기-이용-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>2.1 나이브 베이즈 분류기 이용</a></span></li><li><span><a href=\"#2.2-로지스틱-회귀분석-이용\" data-toc-modified-id=\"2.2-로지스틱-회귀분석-이용-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>2.2 로지스틱 회귀분석 이용</a></span></li><li><span><a href=\"#2.3-릿지-회귀-이용\" data-toc-modified-id=\"2.3-릿지-회귀-이용-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>2.3 릿지 회귀 이용</a></span></li><li><span><a href=\"#2.4-라쏘-회귀-이용\" data-toc-modified-id=\"2.4-라쏘-회귀-이용-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>2.4 라쏘 회귀 이용</a></span></li><li><span><a href=\"#2.5-결정-트리-이용\" data-toc-modified-id=\"2.5-결정-트리-이용-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>2.5 결정 트리 이용</a></span></li><li><span><a href=\"#2.6-랜덤-포레스트-이용\" data-toc-modified-id=\"2.6-랜덤-포레스트-이용-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>2.6 랜덤 포레스트 이용</a></span></li><li><span><a href=\"#2.7-그래디언트-부스팅-이용\" data-toc-modified-id=\"2.7-그래디언트-부스팅-이용-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>2.7 그래디언트 부스팅 이용</a></span></li></ul></li><li><span><a href=\"#3.-종합적인-결과-보기\" data-toc-modified-id=\"3.-종합적인-결과-보기-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span><strong>3. 종합적인 결과 보기</strong></a></span></li><li><span><a href=\"#4.-test-set에-대해서-분류-예측\" data-toc-modified-id=\"4.-test-set에-대해서-분류-예측-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span><strong>4. test set에 대해서 분류 예측</strong></a></span></li><li><span><a href=\"#5.-author-별로-영향을-많이-미친-특성-혹은-단어-확인\" data-toc-modified-id=\"5.-author-별로-영향을-많이-미친-특성-혹은-단어-확인-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span><strong>5. author 별로 영향을 많이 미친 특성 혹은 단어 확인</strong></a></span></li><li><span><a href=\"#6.-결론\" data-toc-modified-id=\"6.-결론-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span><strong>6. 결론</strong></a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 데이터 준비**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>He was almost choking. There was so much, so m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>“Your sister asked for it, I suppose?”</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>She was engaged one day as she walked, in per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The captain was in the porch, keeping himself ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"It was well fought,\" he said, \"and, by my soo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Not to pay him was impossible, considering his...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>“A proper figure of a man at-arms,” said the l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>'You were not here last Sunday night,' he said.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>“You must not ask me that!” I cried. “Hell may...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  author\n",
       "0      0  He was almost choking. There was so much, so m...       3\n",
       "1      1             “Your sister asked for it, I suppose?”       2\n",
       "2      2   She was engaged one day as she walked, in per...       1\n",
       "3      3  The captain was in the porch, keeping himself ...       4\n",
       "4      4  “Have mercy, gentlemen!” odin flung up his han...       3\n",
       "5      5  \"It was well fought,\" he said, \"and, by my soo...       4\n",
       "6      6  Not to pay him was impossible, considering his...       3\n",
       "7      7  “A proper figure of a man at-arms,” said the l...       2\n",
       "8      8    'You were not here last Sunday night,' he said.       0\n",
       "9      9  “You must not ask me that!” I cried. “Hell may...       4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head(10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 train set과 test set 분할(비율 3:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train set size :  41159\n",
      "# Test set size :  13720\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.author, test_size=0.25, random_state=1)\n",
    "\n",
    "print('# Train set size : ', len(x_train))\n",
    "print('# Test set size : ', len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Train set ###\n",
      "# text sample :  34509     “And then you have added so much to it yourse...\n",
      "15230    Presently, however, the ground began to rise, ...\n",
      "51072    Then followed an obstinate and deadly struggle...\n",
      "11046    “Is a bit thick, you mean? Well, in a way that...\n",
      "52441    'I hear you,' replied the girl, turning her fa...\n",
      "Name: text, dtype: object\n",
      "# author sample :  34509    1\n",
      "15230    4\n",
      "51072    4\n",
      "11046    3\n",
      "52441    0\n",
      "Name: author, dtype: int64\n",
      "\n",
      "### Test set ###\n",
      "# text sample :  41956    “Ah, that’s true! I understand that perfectly ...\n",
      "42056     He took the boots from the bag, and compared ...\n",
      "16422    \"It's not only absurd, but something else as w...\n",
      "22151    \"You're an atheist because you're a snob, a sn...\n",
      "8409     I would not, however, have dwelt on such trivi...\n",
      "Name: text, dtype: object\n",
      "# author sample :  41956    3\n",
      "42056    2\n",
      "16422    3\n",
      "22151    3\n",
      "8409     3\n",
      "Name: author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('### Train set ###')\n",
    "print('# text sample : ', x_train.head())\n",
    "print('# author sample : ', y_train.head())\n",
    "print()\n",
    "\n",
    "print('### Test set ###')\n",
    "print('# text sample : ', x_test.head())\n",
    "print('# author sample : ', y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3 정규표현식을 이용한 토크나이저 함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegTok = RegexpTokenizer(\"[\\w']{3,}\") # 정규표현식 이용\n",
    "\n",
    "stop_words = set(stopwords.words('english')) # 영어 불용어 \n",
    "\n",
    "def tokenizer(text):\n",
    "    tokens = RegTok.tokenize(text.lower())\n",
    "    words = [word for word in tokens if (word not in stop_words) and len(word) > 2] # 불용어 제거\n",
    "    features = (list(map(lambda token:PorterStemmer().stem(token), words))) # 포터 스테머 적용\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.4 TfidfVectorizer에 토큰화 결과를 입력으로 사용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer).fit(x_train)\n",
    "\n",
    "x_train_tfidf = tfidf.fit_transform(x_train)\n",
    "x_test_tfidf = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 첫 번째 문서에 대해서 200개만 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'80' : 0.0, '_c'est : 0.0, '_i_ : 0.0, '_non : 0.0, '_real : 0.0, '_that_ : 0.0, '_there_ : 0.0, '_was_ : 0.0, '_your_ : 0.0, 'a : 0.0, 'a' : 0.0, 'about : 0.0, 'add : 0.0, 'address : 0.0, 'affect : 0.0, 'afraid : 0.0, 'after : 0.0, 'again : 0.0, 'ah : 0.0, 'aha : 0.0, 'ain't : 0.0, 'all : 0.0, 'alway : 0.0, 'am : 0.0, 'amen : 0.0, 'amiabl : 0.0, 'among : 0.0, 'an : 0.0, 'an't : 0.0, 'and : 0.0, 'ani : 0.0, 'anoth : 0.0, 'antimoni : 0.0, 'anyth : 0.0, 'apocalypse' : 0.0, 'appears' : 0.0, 'are : 0.0, 'aro : 0.0, 'ask : 0.0, 'at : 0.0, 'attend : 0.0, 'auld : 0.0, 'ave : 0.0, 'aweel : 0.0, 'ay : 0.0, 'ay' : 0.0, 'back : 0.0, 'bah : 0.0, 'bayton : 0.0, 'be : 0.0, 'bear : 0.0, 'beauti : 0.0, 'becaus : 0.0, 'befor : 0.0, 'bet : 0.0, 'better : 0.0, 'beyond : 0.0, 'bi : 0.0, 'bill : 0.0, 'bister : 0.0, 'black : 0.0, 'blather : 0.0, 'bless : 0.0, 'blood : 0.0, 'blow : 0.0, 'bolter : 0.0, 'bombarded' : 0.0, 'bout : 0.0, 'bow : 0.0, 'box' : 0.0, 'boy : 0.0, 'boy' : 0.0, 'brandish : 0.0, 'brass : 0.0, 'break : 0.0, 'bring : 0.0, 'bull' : 0.0, 'but : 0.0, 'calendar : 0.0, 'call : 0.0, 'can : 0.0, 'can't : 0.0, 'cannot : 0.0, 'cap'n : 0.0, 'caro : 0.0, 'carri : 0.0, 'casimir : 0.0, 'catch : 0.0, 'caus : 0.0, 'celtic : 0.0, 'cept : 0.0, 'certain : 0.0, 'certainli : 0.0, 'chang : 0.0, 'chariti : 0.0, 'christoph : 0.0, 'civil : 0.0, 'clasp : 0.0, 'clear : 0.0, 'clever : 0.0, 'close : 0.0, 'coachman : 0.0, 'coal : 0.0, 'cod : 0.0, 'cold : 0.0, 'combin : 0.0, 'come : 0.0, 'commit : 0.0, 'compos : 0.0, 'congratulate' : 0.0, 'content : 0.0, 'cool : 0.0, 'corner : 0.0, 'could : 0.0, 'couldn't : 0.0, 'cover : 0.0, 'cub : 0.0, 'cut : 0.0, 'd'ye : 0.0, 'damm : 0.0, 'damn : 0.0, 'dark : 0.0, 'darl : 0.0, 'dead : 0.0, 'dear : 0.0, 'dearer : 0.0, 'decidedli : 0.0, 'delight : 0.0, 'dentifi : 0.0, 'depend : 0.0, 'devil' : 0.0, 'did : 0.0, 'didn't : 0.0, 'do : 0.0, 'dobodi : 0.0, 'doctor : 0.0, 'doe : 0.0, 'don't : 0.0, 'done : 0.0, 'dot' : 0.0, 'dow : 0.0, 'down : 0.0, 'drat : 0.0, 'drive : 0.0, 'drop : 0.0, 'dun : 0.0, 'ee : 0.0, 'egad : 0.0, 'eh : 0.0, 'eight : 0.0, 'either : 0.0, 'eleg : 0.0, 'els : 0.0, 'em : 0.0, 'england : 0.0, 'enough : 0.0, 'equality' : 0.0, 'ere : 0.0, 'ere' : 0.0, 'especi : 0.0, 'espirito : 0.0, 'everi : 0.0, 'everybodi : 0.0, 'except : 0.0, 'extraordinari : 0.0, 'famili : 0.0, 'father : 0.0, 'fear : 0.0, 'felip : 0.0, 'fiddl : 0.0, 'fill : 0.0, 'find : 0.0, 'first : 0.0, 'fish : 0.0, 'five : 0.0, 'follow : 0.0, 'for : 0.0, 'fore : 0.0, 'foreign : 0.0, 'forget : 0.0, 'forgiv : 0.0, 'forti : 0.0, 'four : 0.0, 'fri : 0.0, 'frighten : 0.0, 'frob : 0.0, 'from : 0.0, 'gather : 0.0, 'gentl : 0.0, 'gentlemen : 0.0, 'george' : 0.0, 'get : 0.0, 'give : 0.0, 'go : 0.0, 'god : 0.0, 'gold : 0.0, 'good : 0.0, 'great : 0.0, 'grin : 0.0, 'group' : 0.0, "
     ]
    }
   ],
   "source": [
    "for word, count in zip(tfidf.get_feature_names()[:200], x_train_tfidf[0].toarray()[0, :200]):\n",
    "    print(word, ':', count, end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 문서 분류 알고리즘에 적용**\n",
    "\n",
    "### 2.1 나이브 베이즈 분류기 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train set score : 0.734\n",
      "# Test set score : 0.675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "nb_clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "print('# Train set score : {:.3f}'. format(nb_clf.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(nb_clf.score(x_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### alpha=0.01 ###\n",
      "# Train set score : 0.811\n",
      "# Test set score : 0.720\n",
      "\n",
      "### alpha=0.05 ###\n",
      "# Train set score : 0.807\n",
      "# Test set score : 0.722\n",
      "\n",
      "### alpha=1 ###\n",
      "# Train set score : 0.734\n",
      "# Test set score : 0.675\n",
      "\n",
      "### alpha=1.5 ###\n",
      "# Train set score : 0.701\n",
      "# Test set score : 0.648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('### alpha=0.01 ###')\n",
    "nb_clf = MultinomialNB(alpha=0.01)\n",
    "nb_clf.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'. format(nb_clf.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(nb_clf.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### alpha=0.05 ###')\n",
    "nb_clf = MultinomialNB(alpha=0.05)\n",
    "nb_clf.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'. format(nb_clf.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(nb_clf.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### alpha=1 ###')\n",
    "nb_clf = MultinomialNB(alpha=1)\n",
    "nb_clf.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'. format(nb_clf.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(nb_clf.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### alpha=1.5 ###')\n",
    "nb_clf = MultinomialNB(alpha=1.5)\n",
    "nb_clf.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'. format(nb_clf.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(nb_clf.score(x_test_tfidf, y_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***alpha가 0.01일 때 가장 높은 정확도를 보인다.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 로지스틱 회귀분석 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train set score : 0.787\n",
      "# Test set score : 0.713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "print('# Train set score : {:.3f}'.format(lr_clf.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(lr_clf.score(x_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 릿지 회귀 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train set score : 0.842\n",
      "# Test set score : 0.727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge = RidgeClassifier() # alpha=1\n",
    "\n",
    "ridge.fit(x_train_tfidf, y_train)\n",
    "\n",
    "print('# Train set score : {:.3f}'.format(ridge.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(ridge.score(x_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### alpha=1.2 ###\n",
      "# Train set score : 0.839\n",
      "# Test set score : 0.727\n",
      "\n",
      "### alpha=1.5 ###\n",
      "# Train set score : 0.834\n",
      "# Test set score : 0.726\n",
      "\n",
      "### alpha=2 ###\n",
      "# Train set score : 0.826\n",
      "# Test set score : 0.725\n",
      "\n",
      "### alpha=2.5 ###\n",
      "# Train set score : 0.820\n",
      "# Test set score : 0.724\n",
      "\n",
      "### alpha=3 ###\n",
      "# Train set score : 0.814\n",
      "# Test set score : 0.723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('### alpha=1.2 ###')\n",
    "ridge = RidgeClassifier(alpha=1.2)\n",
    "ridge.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'.format(ridge.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(ridge.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### alpha=1.5 ###')\n",
    "ridge = RidgeClassifier(alpha=1.5)\n",
    "ridge.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'.format(ridge.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(ridge.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### alpha=2 ###')\n",
    "ridge = RidgeClassifier(alpha=2)\n",
    "ridge.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'.format(ridge.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(ridge.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### alpha=2.5 ###')\n",
    "ridge = RidgeClassifier(alpha=2.5)\n",
    "ridge.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'.format(ridge.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(ridge.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### alpha=3 ###')\n",
    "ridge = RidgeClassifier(alpha=3)\n",
    "ridge.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'.format(ridge.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(ridge.score(x_test_tfidf, y_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***릿지 회귀에서 최적의 alpha는 기본 값인 1에서 train set에서는 84,2%, test set에서는 72.7%로 정확성이 가장 높다.***\n",
    "\n",
    "### 2.4 라쏘 회귀 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train set score : 0.755\n",
      "# Test set score : 0.696\n"
     ]
    }
   ],
   "source": [
    "lasso = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
    "\n",
    "lasso.fit(x_train_tfidf, y_train)\n",
    "\n",
    "print('# Train set score : {:.3f}'.format(lasso.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(lasso.score(x_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### C = 0.8 ###\n",
      "# Train set score : 0.736\n",
      "# Test set score : 0.687\n",
      "\n",
      "### C = 0.5 ###\n",
      "# Train set score : 0.695\n",
      "# Test set score : 0.660\n",
      "\n",
      "### C = 0.1 ###\n",
      "# Train set score : 0.530\n",
      "# Test set score : 0.527\n",
      "\n",
      "### C = 0.01 ###\n",
      "# Train set score : 0.318\n",
      "# Test set score : 0.321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('### C = 0.8 ###')\n",
    "lasso = LogisticRegression(penalty='l1', solver='liblinear', C=0.8)\n",
    "lasso.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'.format(lasso.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(lasso.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### C = 0.5 ###')\n",
    "lasso = LogisticRegression(penalty='l1', solver='liblinear', C=0.5)\n",
    "lasso.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'.format(lasso.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(lasso.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### C = 0.1 ###')\n",
    "lasso = LogisticRegression(penalty='l1', solver='liblinear', C=0.1)\n",
    "lasso.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'.format(lasso.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(lasso.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### C = 0.01 ###')\n",
    "lasso = LogisticRegression(penalty='l1', solver='liblinear', C=0.01)\n",
    "lasso.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'.format(lasso.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(lasso.score(x_test_tfidf, y_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***라쏘 회귀에서 C가 1일 때 train set에서는 75.5%, test set에서는 69.6%의 정확도로 가장 높다.***\n",
    "\n",
    "### 2.5 결정 트리 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train set score : 0.994\n",
      "# Test set score : 0.444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dec_tree = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "dec_tree.fit(x_train_tfidf, y_train)\n",
    "\n",
    "print('# Train set score : {:.3f}'.format(dec_tree.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(dec_tree.score(x_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train set에 대해서는 99.4%인 반면 test set에 대해서는 44.4%로 정확도에 큰 차이가 있어 과적합 되었다고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 랜덤 포레스트 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train set score : 0.984\n",
      "# Test set score : 0.519\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "\n",
    "forest.fit(x_train_tfidf, y_train)\n",
    "\n",
    "print('# Train set score : {:.3f}'.format(forest.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(forest.score(x_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 포레스트를 사용했을 때도 마찬가지로 결정트리와 비슷하게 train set에 대해서는 정확도가 높은 반면에 test set에 대해서는 훨씬 낮기 때문에 과적합 되었다고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 그래디언트 부스팅 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train set score : 0.565\n",
      "# Test set score : 0.540\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "gb_clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "print('# Train set score : {:.3f}'.format(gb_clf.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(gb_clf.score(x_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train set에 대해서는 56.5%, test set에 대해서는 54.0%의 정확도로 과적합 되었다고 판단되지는 않지만 정확도가 떨어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. 종합적인 결과 보기**\n",
    "\n",
    "**(결정트리, 랜덤 포레스트, 그래디언트 부스팅 제외)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Naive_Bayes Classifier ###\n",
      "# Train set score : 0.811\n",
      "# Test set score : 0.720\n",
      "\n",
      "### Logistic_Regression Classifier ###\n",
      "# Train set score : 0.787\n",
      "# Test set score : 0.713\n",
      "\n",
      "### Ridge Classifier ###\n",
      "# Train set score : 0.842\n",
      "# Test set score : 0.727\n",
      "\n",
      "### Lasso Classifier ###\n",
      "# Train set score : 0.755\n",
      "# Test set score : 0.696\n"
     ]
    }
   ],
   "source": [
    "print('### Naive_Bayes Classifier ###') # alpha가 0.01일 때 가장 높은 정확도 \n",
    "nb_clf = MultinomialNB(alpha=0.01)\n",
    "nb_clf.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'. format(nb_clf.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(nb_clf.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### Logistic_Regression Classifier ###')\n",
    "print('# Train set score : {:.3f}'.format(lr_clf.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(lr_clf.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### Ridge Classifier ###') # alpha=1일 떄 가장 높은 정확도\n",
    "ridge = RidgeClassifier() \n",
    "ridge.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'.format(ridge.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(ridge.score(x_test_tfidf, y_test)))\n",
    "print()\n",
    "\n",
    "print('### Lasso Classifier ###') # C가 1일 때 가장 높은 정확도\n",
    "lasso = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
    "lasso.fit(x_train_tfidf, y_train)\n",
    "print('# Train set score : {:.3f}'.format(lasso.score(x_train_tfidf, y_train)))\n",
    "print('# Test set score : {:.3f}'.format(lasso.score(x_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***릿지 회귀를 이용한 분류기의 경우가 train set에서는 83.4%, test set에 대해서는 72.6%로 가장 높은 정확도를 갖는다.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. test set에 대해서 분류 예측**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41956</th>\n",
       "      <td>“Ah, that’s true! I understand that perfectly ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42056</th>\n",
       "      <td>He took the boots from the bag, and compared ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16422</th>\n",
       "      <td>\"It's not only absurd, but something else as w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22151</th>\n",
       "      <td>\"You're an atheist because you're a snob, a sn...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8409</th>\n",
       "      <td>I would not, however, have dwelt on such trivi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46026</th>\n",
       "      <td>“Mr. Hands,” he said, “here are two of us with...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>“We'll never get ashore at this rate,” said I.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45368</th>\n",
       "      <td>“And now speak to your father, dearest. No oth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19300</th>\n",
       "      <td>As he spoke, a French squire and the Bohemian ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41708</th>\n",
       "      <td>If I were still not brought to reason by all t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "41956  “Ah, that’s true! I understand that perfectly ...       3\n",
       "42056   He took the boots from the bag, and compared ...       2\n",
       "16422  \"It's not only absurd, but something else as w...       3\n",
       "22151  \"You're an atheist because you're a snob, a sn...       3\n",
       "8409   I would not, however, have dwelt on such trivi...       3\n",
       "46026  “Mr. Hands,” he said, “here are two of us with...       4\n",
       "85        “We'll never get ashore at this rate,” said I.       4\n",
       "45368  “And now speak to your father, dearest. No oth...       0\n",
       "19300  As he spoke, a French squire and the Bohemian ...       2\n",
       "41708  If I were still not brought to reason by all t...       3"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([x_test[:10], y_test[:10]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# author 분류 결과 :  [1 2 3 3 3 2 4 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "pred_head = ridge.predict(x_test_tfidf[:10])\n",
    "\n",
    "print('# author 분류 결과 : ', pred_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***앞의 10개의 소설 중 8개는 올바르게 분류되었고 2개는 제대로 분류되지 않았다.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37943</th>\n",
       "      <td>'Conkey means Nosey, ma'am,' interposed Duff.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38349</th>\n",
       "      <td>Every object in the next day’s journey was ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10029</th>\n",
       "      <td>“You may smile,--but there’s a career in this,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28874</th>\n",
       "      <td>\"Swear to me that he still lives,\" she returned.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21086</th>\n",
       "      <td>‘Aye, aye?’ said odin, returning. ‘I am glad t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30720</th>\n",
       "      <td>\"Oh, that's the best explanation you can give,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45434</th>\n",
       "      <td>'Know me!' cried odin. 'Who can do so? My life...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>\"We shall fight at daybreak, that's a settled ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>With that, odin, who was flushed with walking,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26233</th>\n",
       "      <td>“Can ye so, indeed?” asked the Jacobite. “Well...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "37943      'Conkey means Nosey, ma'am,' interposed Duff.       0\n",
       "38349   Every object in the next day’s journey was ne...       1\n",
       "10029  “You may smile,--but there’s a career in this,...       3\n",
       "28874   \"Swear to me that he still lives,\" she returned.       4\n",
       "21086  ‘Aye, aye?’ said odin, returning. ‘I am glad t...       0\n",
       "30720  \"Oh, that's the best explanation you can give,...       2\n",
       "45434  'Know me!' cried odin. 'Who can do so? My life...       4\n",
       "5848   \"We shall fight at daybreak, that's a settled ...       3\n",
       "1616   With that, odin, who was flushed with walking,...       0\n",
       "26233  “Can ye so, indeed?” asked the Jacobite. “Well...       4"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([x_test[-10:], y_test[-10:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# author 분류 결과 :  [0 1 3 4 4 3 3 3 0 4]\n"
     ]
    }
   ],
   "source": [
    "pred_tail = ridge.predict(x_test_tfidf[-10:])\n",
    "\n",
    "print('# author 분류 결과 : ', pred_tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***뒤의 10개의 소설 중에서도 7개는 올바르게 분류되었지만 3개는 잘못 분류 되었다.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. author 별로 영향을 많이 미친 특성 혹은 단어 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def top_features(classifier, vectorizer, categories, n):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    \n",
    "    for i, category in enumerate(categories):\n",
    "        top = np.argsort(-classifier.coef_[i])[:n]\n",
    "        print('%s: %s' % (category, ', '.join(feature_names[top])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: dora, darnay, joe, aunt, jerri, carton, handel, pip, creakl, crupp\n",
      "1: ferrier, luci, lizzi, ann, shew, surpriz, tilney, jane, margaret, maria\n",
      "2: inspector, professor, hordl, nigel, hudson, moor, bork, bowman, straker, pinner\n",
      "3: princ, roubl, stepan, totski, moscow, ivan, suddenli, podincutor, simpli, zossimov\n",
      "4: sila, casimir, villon, florizel, stubb, countess, silver, marjori, pool, balli\n"
     ]
    }
   ],
   "source": [
    "top_features(ridge, tfidf, authors, 10) # 상위 10개의 단어 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. 결론**\n",
    "\n",
    "**릿지 회귀**에 데이터를 적용했을 때 **train set에서는 84.2%, test set에서는 72.7%의 정확도**로 나이브 베이즈 분류기, 로지스틱 회귀, 라쏘 회귀 등에 적용했을 때보다 정확성이 높게 나타난다. 결정트리와 결정트리 기반의 앙상블 모형 중 랜덤포레스트 모형은 train set에서는 98%가 넘는 정확도로 매우 높게 나타나지만 test set에서는 각각 44.4%, 51.9%의 정확도로 매우 낮기 때문에 과대적합 되었다고 할 수 있다. 또한 결정트리 기반의 그래디언트 부스팅은 train set과 test set에서 모두 50% 대의 정확도로 낮은 정확성을 갖고 있다고 할 수 있다.\n",
    "\n",
    "따라서 test set에서 앞에 10개, 뒤에 10개를 text와 author를 출력해 릿지 회귀를 통해 분류해본 결과 **총 20개의 소설 중 5개가 잘못 분류**되어 약 75%의 정확도를 보이는 것을 알 수 있다.\n",
    "\n",
    "또한 author 별로 어떤 단어가 큰 영향을 주는지 상위 10개를 출력해본 결과, 다음과 같은 단어들의 영향이 크게 나타났다.\n",
    "\n",
    "* **작가가 0**인 소설 : dora, darnay, joe, aunt, jerri, carton, handel, pip, creakl, crupp\n",
    "* **작가가 1**인 소설 : ferrier, luci, lizzi, ann, shew, surpriz, tilney, jane, margaret, maria\n",
    "* **작가가 2**인 소설 : inspector, professor, hordl, nigel, hudson, moor, bork, bowman, straker, pinner\n",
    "* **작가가 3**인 소설 : princ, roubl, stepan, totski, moscow, ivan, suddenli, podincutor, simpli, zossimov\n",
    "* **작가가 4**인 소설 : sila, casimir, villon, florizel, stubb, countess, silver, marjori, pool, balli"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "646.667px",
    "left": "911px",
    "top": "309.778px",
    "width": "341.306px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
